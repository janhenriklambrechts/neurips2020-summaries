## A Few Lessons Learned

| Date | Title | Speaker | Type |   
| ---- | ----- | ------- | ---- |
| 07/12/2020 | A Few Lessons Learned | Samy Bengio | Expo-Workshop |

### Doing a PhD?
- So you have a CS diploma from an unknown university (University of Montreal was unknown back then)
-> **Lesson 1: Dont plan your whole life ahead! Taking steps back is OK!**

### How to choose your thesis topic... in 1989
- Back then AI is all about expert systems and case based reasoning 
- Already during masters thesis Samy realised that expert systems were not gonna be good for real-life use cases
- Samy was the first student working on that topic in his uni and no professors but he convinced a friend to be his advisor
- Neural nets were not trendy, so there were no grants - but the interest in understanding how the brain works was very strong
- They were using SGD back then -> Yes! Still the same! -> Can we add parameters to SGD to make it better
- There is always someone else working on the same topic as you and that is okay :)
- Computers were not very good but it was working... many years before NAS and AutoML
- **Lesson 2: Taking risk is part of the job** -> Choosing something far from others reduced risk of getting scooped

### Open Sourcing
- Finished PhD, did some postdocs
- Money comes from grants, so he learns how to write grants
- 1999: SVMs are now all the trend
- His PhD student develops SVMTorch for first issue of JMLR, this was in a time when 20.000 data points was huge!
- They open source this library, as they extend it to neural nets
- They kept changing this library and it became PyTorch eventually, Roland is now at FAIR 
- **Lesson 3: Show your work**: Open Source was huge for them and all the effort it took was worth it

### Other forms of impact
- At 2007, he wants to move to industry, back then Google Research is 100 people -> Now 3000
- At the time he gets complete freedom -> Very scary -> He decides to look at all the products and see where ML could contribute
- Back then Google Image Search was all based on text around the images -> So they proposed a ranking algorithm for images given queries based on pixels -> Problem: algo doesnt scale -> But wait, at Google they know a lot about scale -> + a huge amount of product constraints: robustness, spam, time, politics, etc.
- **Lesson 4: Multiple forms of impact**: Hurdles towards building a product are real but they are worth it
- "Theory and practice are the same in theory, but not in practice" :)

### Brain: Exploration is Key
- 2012: Deep Learning becomes a thing and they decide to explore it at Google
- They impacted a really big part of Google Products
- Rapid disorganized growth leads to less diversity and less inclusion
- **Lesson 5: Exploration is Key** -> Favor diversity, inclusion and provide research freedom

